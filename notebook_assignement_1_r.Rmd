---
title: "R Notebook"
output: html_notebook
---

Patrecog assignement in R

The data file mnist.csv contains gray-scale images of hand-drawn digits, from zero through nine.

Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, 
indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.

The data set has 785 columns. The first column, called \"label\", is the digit that was written by the user. 
The rest of the columns contain the pixel-values of the associated image.

Each pixel column in the data set has a name like pixelx, where x is an integer between 0 and 783, inclusive. 
To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. 
Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).

For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.

Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:

000 001 002 ... 028\
029 030 031 ... 056\ 
...\
(its 28 x 28)

```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library("OpenImageR")
mnist.dat = read.csv("mnist.csv")
dim(mnist.dat)
#imageShow(matrix(as.numeric(mnist.dat[380,-1]),nrow=28,ncol=28,byrow=T))
```


Part 1---------------------------------------------\
Begin with an exploratory analysis of the data. 
Can you spot useless variables by looking at their summary statisitcs? 
Consider the class distribution: what percentage of cases would be classified correctly if we simply predict the majority class? 
Convert the first column (the digit) to a categorical variable using "as.factor" in R.
Report any findings from your exploratory analysis that you think are of interest.

```{r}
get_useless_indexes <- function(matrix){
  useless_pixels <- c() # these are always 1 value and dont change, so they are useless for informing our model
  for (i in 1:dim(matrix)[2]){
    unique_pixel_values <- unique(matrix[,i])
    if (length(unique_pixel_values)==1){ 
      useless_pixels <- c(useless_pixels,i)
    }
  }
  return(useless_pixels)
}

useless_mnist_pixels <- get_useless_indexes(mnist.dat)
mnist.dat[,1] <- as.factor(mnist.dat[,1]) # get all values from the first column (the number on the image)
y <- mnist.dat[,1] # this is just a vector of the classes now

number_of_entries <- dim(mnist.dat)[1] #first dimension of the dataset is the number of rows


majority_class = rev(sort(table(y)))[1]
correct_pred <- mnist.dat[mnist.dat[,1] == "1",]
correct_pred <- dim(correct_pred)[1]
accuracy = correct_pred / number_of_entries

```
How many times each class occurs:
```{r}
rev(sort(table(y))) # reverses a sorted table of how many times each class (factor) occurs
```

Accuracy with majority classifier:
```{r}
accuracy
```
Useless pixels (indexes, to get pixel subtract 1):
```{r}
useless_mnist_pixels
```



Part 2---------------------------------------------\
Derive from the raw pixel data a feature that quantifies "how much ink" a digit costs.
Report the average and standard deviation of this feature within each class. 
If you look at these statistics, can you see which pairs of classes can be distinguished well, and which pairs will be hard to distinguish using this feature?
  Hint: Use the R function "tapply" to compute the mean and standard deviation per digit. 
If your feature is called "ink", then "tapply(ink,mnist.dat[,1],mean)" will compute the mean value of ink for each digit.

```{r}
library(nnet)

ink_sum <- apply(mnist.dat[,-1],MARGIN=1,FUN=sum)  # Margin means do function on every row
ink_mean <- apply(mnist.dat[,-1],MARGIN=1,FUN=mean)  # Margin means do function on every row
ink_sd <- apply(mnist.dat[,-1],MARGIN=1,FUN=sd)  # Margin means do function on every row
# add the means, sd, for each class (unique numbers)
ink_scaled <- rep(c(0),length(ink_sum))
mnist.dat <- cbind(ink_sum,ink_mean,ink_sd,mnist.dat)


digit_sd <- aggregate(mnist.dat$ink_sum,by=list(mnist.dat$label),FUN=sd )
digit_mean <- aggregate(mnist.dat$ink_sum,by=list(mnist.dat$label),FUN=mean )
```
Digit mean:
```{r}
digit_mean
```


Digit Standard Deviation:
```{r}
digit_sd
```



Using only the ink feature, fit a multinomial logit model and evaluate,
by looking at the confusion matrix, how well this model can distinguish between the different classes.
Since in this part of the assignment we only consider very simple models, 
you may use the complete data set both for training and evaluation.

```{r}
mnist.dat$ink_scaled <- scale(mnist.dat$ink_sum,scale=max(mnist.dat$ink_sum),center=FALSE)

new_df <- data.frame(mnist.dat$label,mnist.dat$ink_scaled)
colnames(new_df) <- c("label","ink_scaled")

multinom <- multinom(new_df$label ~ new_df$ink_scaled)
multinom.pred <- predict(multinom,new_df$ink_scaled)
table(new_df$label,multinom.pred)
```



For example, how well can the model distinguish between the digits 
"1" and "8"? And how well between "3" and "8"? 
Use the R function "scale" to scale your feature before you apply "multinom" to fit the multinomial logit model.


ANSWER:\
The model is relatively good at detecting 0's and 1's, it has a hard time distinguishing between the other numbers though, with sometimes close to equal probabilities across the board.

I think this is because the means and standard deviations for digits 4 5 and 6 are somewhat simillar, so based on the sum ink feature alone it cannot distinguish between them and a 7, that is also simillar but occurs more often. In general when the values are simillar it seems to pick the most likely number based on the dataset.

the model cannot distinguish between 3 and 8 at all
 it didnt predict a 8 once, and predicted an 8 being a 3, more times than itpredicted a 3 correctly
 it can distinguish between 1 and 8 pretty well, it incorrectly predicted
 an 8 being a 1 140 times, but predicted 1 correctly 2856 times

Part 3 -------------------------------------------\
In addition to "ink", come up with one other feature, and explain why you think it might discriminate well between the digits. Your report should contain an unambiguous description of how the feature is derived from the raw data. Perform the same analysis for this new feature as you did for the ink feature.


Below I use canny edge detector to find how many curves each number has, example below
```{r}
library(magick)
library(png)
dim(mnist.dat[15,5:788])

test_image <- matrix(as.numeric(mnist.dat[15,5:788]/255),nrow=28,ncol=28,byrow=T) # get an 2d 28 x 28 matrix representing the 15th image

test_image_object <- writePNG(test_image) # load the matrix into an image like object 

# To check what the image looks like, paste this into console
#imageShow(matrix(as.numeric(mnist.dat[15,5:788]),nrow=28,ncol=28,byrow=T))
```

What the edge detector output looks like for the test image
```{r}
edges <- image_canny(image_read(test_image_object),geometry="0x1+10%+30%") # Run canny edge detector, the geometry is using the default parameter
edges
```

Below we use hough line transform to detect straight lines in an image,
I fitted the geometry parameter until the output was detecting reasonably straight lines in the 28x28 image)
(what the output looks like is below)
```{r}
hough <- image_hough_draw(edges,geometry="30x30+11",size=0.3,color="white",bg = "black")
gray_image <- image_convert(hough,type="grayscale")
gray_image_data <- as.numeric(image_data(gray_image)) # this function converts the image to a matrix, like the original mnist data, but with lower value ranges (0 to 1) for pixels
gray_image
```



```{r}
# this is just the above code in 1 block to see what different images look like
index_of_image <- 60
test_image <- matrix(as.numeric(mnist.dat[index_of_image,5:788]/255),nrow=28,ncol=28,byrow=T) 
test_image_object <- writePNG(test_image)
edges <- image_canny(image_read(test_image_object),geometry="0x1+10%+30%")
edges
hough <- image_hough_draw(edges,geometry="30x30+11",size=0.3,color="white",bg = "black")
gray_image <- image_convert(hough,type="grayscale")
gray_image
```

Does the above for each image, gets their straight line images, adds them to new mnist like matrix
```{r}
# this will make my own mnist with the straight line detections

#mnist_original = read.csv("mnist.csv")
line_image_matrix <- array(c(0),dim = c(42000,28*28))
```
This took 50 minutes on my machine, but this will be a secret

```{r}
if(!file.exists("line_image_matrix.rds")){
  pb = txtProgressBar(min = 1, max = nrow(mnist.dat), style = 3) 
  
  
  for (image_index in 1:nrow(mnist.dat)){
    image_mat <- matrix(as.numeric(mnist.dat[image_index,5:788]/255),nrow=28,ncol=28,byrow=T)
    image_object <- writePNG(image_mat)
    edges <- image_canny(image_read(image_object),geometry="0x1+10%+30%")
    hough <- image_hough_draw(edges,geometry="30x30+11",size=0.3,color="white",bg = "black")
    gray_image <- image_convert(hough,type="grayscale")
    gray_image_data <- t(as.numeric(image_data(gray_image))[,,1]) # make it 2D
    line_image_matrix[image_index,] <- as.vector(gray_image_data)
    if(image_index %% 100 == 0){
        setTxtProgressBar(pb,image_index)
        #browser()
    }
  
  }
  close(pb)
  #save file so it doesnt have to be calculated again
  saveRDS(line_image_matrix, file = "line_image_matrix.rds")
}else{
  readRDS(file = "line_image_matrix.rds") # skip the below and just read it
  print("done")
}
```

Calculate the ink sum again, but this time its on the images that represent detected straight lines on the mnist images. This, combined with the original ink sum feature of the images will make differentiating between them easier.
```{r}
ink_sum <- apply(line_image_matrix,MARGIN=1,FUN=sum) 
straight_line_df <- cbind(ink_sum,y,line_image_matrix)
```
Mean of these new straight images
```{r}
straightness_sd <- aggregate(straight_line_df[,1],by=list(straight_line_df[,2]),FUN=sd )
straightness_mean <- aggregate(straight_line_df[,1],by=list(straight_line_df[,2]),FUN=mean )
straightness_mean

```
SD:
```{r}
straightness_sd
```
Now we fit it to the multinomial classifier:
```{r}
ink_scaled <- scale(ink_sum,scale=max(ink_sum))

new_df <- data.frame(mnist.dat$label,mnist.dat$ink_scaled,ink_scaled)
colnames(new_df) <- c("label","ink_scaled","straight_line_scaled")

multinom <- multinom(new_df$label ~ ., data = new_df)
multinom.pred <- predict(multinom,new_df[,-1])
table(new_df$label,multinom.pred)
```


